{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines for Druggable peptide classifiers using di-aminoacid composition descriptors (DC)\n",
    "\n",
    "For each dataset, classifier and folds:\n",
    "- scaling\n",
    "- feature selection\n",
    "- outerCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# remove warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, roc_auc_score,f1_score, recall_score, precision_score\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.feature_selection import RFECV, VarianceThreshold, SelectKBest, chi2\n",
    "from sklearn.feature_selection import SelectFromModel, SelectPercentile, f_classif\n",
    "\n",
    "import seaborn as sns; sns.set() # data visualization library \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define script parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define output variables\n",
    "outVars = ['Class']\n",
    "\n",
    "# define list of folds\n",
    "foldTypes = [3]\n",
    "\n",
    "# define a label for output files\n",
    "targetName = 'DC_Outer'\n",
    "\n",
    "seed = 28"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  set_weights(y_data, option='balanced'):\n",
    "    \"\"\"Estimate class weights for umbalanced dataset\n",
    "       If ‘balanced’, class weights will be given by n_samples / (n_classes * np.bincount(y)). \n",
    "       If a dictionary is given, keys are classes and values are corresponding class weights. \n",
    "       If None is given, the class weights will be uniform \"\"\"\n",
    "    cw = class_weight.compute_class_weight(option, np.unique(y_data), y_data)\n",
    "    w = {i:j for i,j in zip(np.unique(y_data), cw)}\n",
    "    return w "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataCheckings(df):\n",
    "    # CHECKINGS ***************************\n",
    "    # Check the number of data points in the data set\n",
    "    print(\"\\nData points =\", len(df))\n",
    "    \n",
    "    # Check the number of columns in the data set\n",
    "    print(\"\\nColumns (output + features)=\",len(df.columns))\n",
    "    \n",
    "    # Check the data types\n",
    "    print(\"\\nData types =\", df.dtypes.unique())\n",
    "    \n",
    "    # Dataset statistics\n",
    "    print('\\n')\n",
    "    df.describe()\n",
    "    \n",
    "    # print names of columns\n",
    "    print('Column Names:\\n', df.columns)\n",
    "    \n",
    "    # see if there are categorical data\n",
    "    print(\"\\nCategorical features:\", df.select_dtypes(include=['O']).columns.tolist())\n",
    "    \n",
    "    # Check NA values\n",
    "    # Check any number of columns with NaN\n",
    "    print(\"\\nColumns with NaN: \", df.isnull().any().sum(), ' / ', len(df.columns))\n",
    "\n",
    "    # Check any number of data points with NaN\n",
    "    print(\"\\nNo of data points with NaN:\", df.isnull().any(axis=1).sum(), ' / ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDataFromDataset(sFile, OutVar):\n",
    "    # read details file\n",
    "    print('\\n-> Read dataset', sFile)\n",
    "    df = pd.read_csv(sFile)\n",
    "    #df = feather.read_dataframe(sFile)\n",
    "    \n",
    "    DataCheckings(df)\n",
    "    \n",
    "    # remove duplicates!\n",
    "    df.drop_duplicates(keep=False, inplace=True)\n",
    "    \n",
    "    print('Shape', df.shape)\n",
    "    # print(list(df.columns))\n",
    "\n",
    "    # select X and Y\n",
    "    ds_y = df[OutVar]\n",
    "    ds_X = df.drop(OutVar,axis = 1)\n",
    "    Xdata = ds_X.values # get values of features\n",
    "    Ydata = ds_y.values # get output values\n",
    "\n",
    "    print('Shape X data:', Xdata.shape)\n",
    "    print('Shape Y data:',Ydata.shape)\n",
    "    \n",
    "    # return data for X and Y, feature names as list\n",
    "    return (Xdata, Ydata, list(ds_X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OutVar = outVars[0]\n",
    "folds  = foldTypes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from file\n",
    "sFile = './datasets/ds.Class_DC.csv'\n",
    "Xdata, Ydata, Features = getDataFromDataset(sFile,OutVar)\n",
    "    \n",
    "smote = SMOTE(ratio='minority',random_state=seed)\n",
    "X_sm, y_sm = smote.fit_sample(Xdata, Ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unballanced dataset\n",
    "ax = sns.countplot(Ydata,label=\"Count\")      # count 1 and 0 in target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ballanced dataset\n",
    "ax = sns.countplot(y_sm,label=\"Count\")      # count 1 and 0 in target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the ballanced dataset or skip this block:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save ballanced dataset\n",
    "df_balanced = pd.DataFrame(X_sm,columns=Features)\n",
    "df_balanced['Class']=y_sm\n",
    "df_balanced.to_csv('./datasets/ds.Class_DC_ballanced.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main ML pipeline code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pipeline_OuterCV(Xdata, Ydata, label = 'my', class_weights = {0: 1, 1: 1}, folds = 3, seed = 42):\n",
    "    # inputs:\n",
    "    # data for X, Y; a label about data, number of folds, seeed\n",
    "    \n",
    "    # default: 3-fold CV, 1:1 class weights (ballanced dataset)\n",
    "    \n",
    "    # define classifiers\n",
    "    names = ['NB','KNN','LDA','SVM linear','SVM','LR','MLP','DT','RF','XGB','GB','AdaB','Bagging'] \n",
    "    \n",
    "    \n",
    "    priors = [(class_weights[0]/(class_weights[0]+class_weights[1])), (class_weights[1]/(class_weights[0]+class_weights[1]))]\n",
    "    \n",
    "    neurons = Xdata.shape[1] # neurons for MLP = number of input features\n",
    "    \n",
    "    classifiers = [GaussianNB(),\n",
    "                   KNeighborsClassifier(3),\n",
    "                   LinearDiscriminantAnalysis(solver='svd',priors=priors), # No tiene random_state\n",
    "                   SVC(kernel=\"linear\",random_state=seed,gamma='scale',class_weight=class_weights),\n",
    "                   SVC(kernel = 'rbf', random_state=seed,gamma='scale',class_weight=class_weights),\n",
    "                   LogisticRegression(solver='lbfgs',random_state=seed,class_weight=class_weights),\n",
    "                   MLPClassifier(hidden_layer_sizes= (20), random_state = seed, max_iter=50000, shuffle=False),\n",
    "                   DecisionTreeClassifier(random_state = seed,class_weight=class_weights),\n",
    "                   RandomForestClassifier(n_jobs=-1,random_state=seed,class_weight=class_weights),\n",
    "                   XGBClassifier(n_jobs=-1,seed=seed,scale_pos_weight= class_weights[0]/class_weights[1]),\n",
    "                   GradientBoostingClassifier(random_state=seed),\n",
    "                   AdaBoostClassifier(random_state = seed),\n",
    "                   BaggingClassifier(random_state=seed)\n",
    "                  ]\n",
    "    # results dataframe: each column for a classifier\n",
    "    df_res = pd.DataFrame(columns=names)\n",
    "\n",
    "    # build each classifier\n",
    "    print('* Building scaling+feature selection+outer '+str(folds)+'-fold CV for '+str(len(names))+' classifiers:', str(names))\n",
    "    total = time.time()\n",
    "    \n",
    "    # define a fold-CV for all the classifier\n",
    "    outer_cv = StratifiedKFold(n_splits=folds,shuffle=True,random_state=seed)\n",
    "    \n",
    "    print('ML method, Mean, SD, Time (min)')\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        start = time.time()\n",
    "        \n",
    "        # create pipeline: scaler + classifier\n",
    "        estimators = []\n",
    "        \n",
    "        # SCALER\n",
    "        # MinMaxScaler(), StandardScaler(), RobustScaler(), QuantileTransformer(), PowerTransformer()\n",
    "        estimators.append(( 'Scaler', StandardScaler() ))\n",
    "        \n",
    "        # FEATURE SELECTOR\n",
    "        estimators.append((  'FS', SelectFromModel(LinearSVC(), max_features = 20,threshold=-np.inf)  ))\n",
    "        \n",
    "        # add Classifier\n",
    "        estimators.append(('Classifier', clf)) \n",
    "        \n",
    "        # create pipeline\n",
    "        model = Pipeline(estimators)\n",
    "        \n",
    "        # evaluate pipeline\n",
    "        scores = cross_val_score(model, Xdata, Ydata, cv=outer_cv, scoring='roc_auc', n_jobs=-1)\n",
    "        \n",
    "        df_res[name] = scores\n",
    "        print('%s, %0.3f, %0.4f, %0.1f' % (name, scores.mean(), scores.std(), (time.time() - start)/60))\n",
    "        \n",
    "    print('Total time:', (time.time() - total)/60, ' mins')             \n",
    "    \n",
    "    # return AUC scores for all classifiers as dataframe (each column a classifier)\n",
    "    return df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_weights = set_weights(y_sm)\n",
    "print(\"Class weights = \", class_weights)\n",
    "\n",
    "df_results = None # all results \n",
    "\n",
    "# try different folds for each subset -> box plots\n",
    "for folds in foldTypes:\n",
    "    df_fold = Pipeline_OuterCV(X_sm, y_sm, label = OutVar, class_weights = class_weights, folds = folds, seed = seed)\n",
    "    df_fold['Dataset'] = OutVar\n",
    "    df_fold['folds'] = folds\n",
    "\n",
    "    # add each result to a summary dataframe\n",
    "    df_results = pd.concat([df_results,df_fold])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all results\n",
    "summaryFile = './results/DC.s.LinearSVC20.csv'\n",
    "print('\\n==>> Saving summary', summaryFile)\n",
    "df_results.to_csv(summaryFile, index=False)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierNames = list(df_results.columns)\n",
    "classifierNames.remove('Dataset')\n",
    "classifierNames.remove('folds')\n",
    "classifierNames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foldTypes = list(set(df_results['folds']))\n",
    "foldTypes.sort()\n",
    "foldTypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in foldTypes:\n",
    "    plt.figure()\n",
    "    plt.clf()\n",
    "    print('==> Fold =', f)\n",
    "    grouped = df_results[df_results['folds']==f].drop(['folds'], axis=1).groupby('Dataset')\n",
    "    grouped.boxplot(figsize=(16,12), return_type='axes')\n",
    "    plt.savefig('./results/DC.s.LinearSVC20.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Have fun! @muntisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
